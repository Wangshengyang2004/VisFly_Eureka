# VisFly-Eureka Main Configuration
# This is the main config file that references specific algorithm and environment configs

defaults:
  - task: hover
  - llm: test
  - agent: minimax
  - mode: eureka
  - api_keys
  - _self_

# Global pipeline settings
pipeline:
  name: "quadro_llm_optimization"
  output_dir: "./results"
  seed: 42
  
# Optimization parameters
optimization:
  iterations: 15           # Number of optimization iterations
  samples: 5          # Reward functions per iteration
  algorithm: "bptt"      # Training algorithm: "bptt", "ppo", or "shac"
  evaluation_episodes: 1  # Episodes for final evaluation
  record_video: true       # Enable video recording during evaluation
  gpu_memory_requirement_mb: 1024
  # History pruning: number of recent iterations to include in LLM context
  # -1 = keep all history (no pruning)
  # 0 = only keep current iteration
  # 1 = keep last iteration
  # 2+ = keep last N iterations (balanced approach, recommended: 2)
  history_window_size: 4

training:
  # Global overrides (optional)
  save_dir: "./results/training"
  comment: "quadro_llm_experiment"

# Execution settings
execution:
  device: "cuda"  # "cuda" or "cpu"
  workload_ratio: 2  # Workers per GPU ratio (default: 2x GPU count)
  
# Logging and monitoring
logging:
  level: "DEBUG"
  save_tensorboard: true
  save_all_functions: true

# Prompt configuration for LLM
prompt:
  include_human_reward: true
  num_alternative_directions: 3  # 0=off; 1,2,3,...=number of directions from Agent Voter

# Hydra configuration
hydra:
  run:
    dir: ./results/${now:%Y-%m-%d_%H-%M-%S}
  job:
    name: quadro_llm_optimization
