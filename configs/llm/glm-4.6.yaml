llm:
  vendor: "bigmodel"
  model: "glm-4.6"
  temperature: 1.0
  timeout: 120
  max_retries: 3
  thinking:
    enabled: true
  batching:
    strategy: "adaptive"
    supports_n_parameter: true
    max_concurrent: 8
