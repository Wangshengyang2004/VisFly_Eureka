llm:
  vendor: "minimax_coding"
  model: "MiniMax-M2.1"
  temperature: 1.0
  timeout: 120
  max_retries: 3
  thinking:
    enabled: true
  batching:
    strategy: "async"
    supports_n_parameter: false
    max_concurrent: 3

