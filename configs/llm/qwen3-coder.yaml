llm:
  vendor: "siliconflow"
  model: "Qwen/Qwen3-Coder-480B-A35B-Instruct"

  # Generation parameters
  temperature: 1.0
  max_tokens: 8192
  top_p: 0.95
  frequency_penalty: 0.0
  presence_penalty: 0.0

  # Request settings
  timeout: 120
  max_retries: 3
  request_delay: 1.0      # Conservative for stability
  batch_size: 5           # Conservative batch size

  # Advanced settings
  use_chat_completion: true
  system_message_enabled: true
  conversation_memory: true

  thinking:
    enabled: false

  # Batching strategy
  batching:
    supports_n_parameter: true
    strategy: "n_parameter"         # Options: "n_parameter", "sequential", "async", "multiprocessing"
    max_concurrent: 10              # For async/multiprocessing strategies

  prompt:
    include_api_doc: true
    api_doc_path: "api-doc.txt"
