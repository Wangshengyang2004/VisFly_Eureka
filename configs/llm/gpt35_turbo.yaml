# GPT-3.5-turbo configuration (cost-effective option)

# @package _global_
llm:
  provider: "openai"
  model: "gpt-3.5-turbo"
  api_key: "${oc.env:OPENAI_API_KEY}"
  base_url: "https://api.openai.com/v1"
  
  # Generation parameters
  temperature: 0.9        # Higher temperature for more creativity
  max_tokens: 1500        # Slightly less for GPT-3.5
  top_p: 1.0
  frequency_penalty: 0.1  # Encourage diversity
  presence_penalty: 0.1
  
  # Request settings
  timeout: 60
  max_retries: 5
  request_delay: 0.2      # GPT-3.5 has higher rate limits
  batch_size: 15          # Can handle larger batches
  
  # Advanced settings
  use_chat_completion: true
  system_message_enabled: true
  conversation_memory: true