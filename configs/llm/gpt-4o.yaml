llm:
  vendor: "ifopen"
  model: "gpt-4o"
  temperature: 1.0
  timeout: 120
  max_retries: 3
  thinking:
    enabled: true
  batching:
    strategy: "adaptive"
    supports_n_parameter: true
    max_concurrent: 8
