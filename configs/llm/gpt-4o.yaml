# GPT-4o configuration

llm:
  vendor: "aigc35"
  model: "gpt-4o"
  
  # Generation parameters
  temperature: 1.0
  max_tokens: 8192
  top_p: 0.95
  frequency_penalty: 0.0
  presence_penalty: 0.0
  
  # Request settings
  timeout: 120
  max_retries: 3
  request_delay: 1.0      # OpenAI has stricter rate limits
  batch_size: 5           # Conservative batch size for OpenAI
  
  # Advanced settings
  use_chat_completion: true
  system_message_enabled: true
  conversation_memory: true
  
  # Batching strategy
  batching:
    supports_n_parameter: true     # OpenAI supports n parameter
    strategy: "n_parameter"        # Options: "n_parameter", "sequential", "async", "multiprocessing"
    max_concurrent: 10             # For async/multiprocessing strategies

  prompt:
    include_api_doc: true
    api_doc_path: "api-doc.txt"
