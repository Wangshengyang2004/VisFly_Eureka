algorithm:
  policy: SimplePolicy
  policy_kwargs:
    features_extractor_class: FlexibleExtractor
    features_extractor_kwargs:
      net_arch:
        state:
          layer: [512]
        depth:
          kernel_size: [8, 4, 3]
          channels: [32, 64, 64]
          stride: [4, 2, 1]
          padding: [0, 0, 0]
          layer: [512]
       
    critic:
      dist: mse
      n_critics: 1
      net_arch:
        layer: [512, 512]
    actor:
      dist: normal
      net_arch:
        layer: [512, 512]

    activation_fn: relu
    optimizer_class: adam
    optimizer_kwargs:
      weight_decay: 0.00001
  
  learning_rate: 0.005
  horizon: 96
  tau: 0.005
  gamma: 0.99
  batch_size: 25600
  train_freq: 96
  gradient_steps: 10
  actor_gradient_steps: 1
  device: cuda

# Learning/training parameters
learn:
  total_timesteps: 5000000
  log_interval: 20

# Test parameters
test:
  is_fig: true
  is_fig_save: true
  is_video: true 
  is_video_save: true
  render_kwargs: {}