# PPO configuration for circling environment
# Aligned with hover/navigation settings

algorithm:
  policy: MultiInputPolicy
  policy_kwargs:
    net_arch: [512, 512]

  learning_rate: 0.0003
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  device: cuda

  # PPO specific
  use_sde: false
  sde_sample_freq: -1

# Learning parameters
learn:
  total_timesteps: 1000000
  log_interval: 10

# Test parameters
test:
  is_fig: true
  is_fig_save: true
  is_video: true
  is_video_save: true
  render_kwargs: {}