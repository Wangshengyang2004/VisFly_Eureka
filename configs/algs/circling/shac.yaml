algorithm:
  policy: SimplePolicy
  policy_kwargs:
    features_extractor_class: StateExtractor
    features_extractor_kwargs:
      net_arch:
        state:
          layer: [512]
    critic:
      dist: mse
      n_critics: 2
      net_arch:
        layer: [512, 512]
    actor:
      dist: normal
      net_arch:
        layer: [512, 512]
    activation_fn: relu
    optimizer_class: adam
    optimizer_kwargs:
      weight_decay: 0.00001
  
  learning_rate: 0.001
  horizon: 32
  tau: 0.005
  gamma: 0.99
  gradient_steps: 5
  buffer_size: 1000000
  batch_size: 200000
  device: cpu

# Environment overrides for SHAC
env_overrides:
  requires_grad: true
  tensor_output: false
  device: cpu
  num_agent_per_scene: 160

# Learning parameters
learn:
  total_timesteps: 50000
  log_interval: 1

# Test parameters
test:
  is_fig: true
  is_fig_save: true
  is_video: true
  is_video_save: true
  render_kwargs: {}
