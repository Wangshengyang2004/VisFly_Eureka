algorithm:
  policy: SimplePolicy
  policy_kwargs:
    features_extractor_class: StateExtractor
    features_extractor_kwargs:
      net_arch:
        state:
          layer: [512, 512]
          ln: True

    critic:
      dist: mse
      n_critics: 2
      net_arch:
        layer: [512, 512, 512]
        ln: True
    actor:
      dist: tanh_normal
      net_arch:
        layer: [512, 512, 512]
        ln: True
    activation_fn: leaky_relu
    optimizer_class: adamW
    optimizer_kwargs:
      weight_decay: 0.0001
    share_features_extractor: False

  learning_rate:
    class: cosine
    kwargs:
      initial: 0.0003
      final: 0.00005
      period: 0.15
  horizon: 96
  tau: 0.005
  gamma: 0.99
  batch_size: 25600
  train_freq: 48
  gradient_steps: 10
  actor_gradient_steps: 1
  device: cuda

# Learning parameters
learn:
  total_timesteps: 200000000
  log_interval: 20
  evaluation_episodes: 10

# Test parameters
test:
  is_fig: true
  is_fig_save: true
  is_video: true
  is_video_save: true
  render_kwargs: {}
